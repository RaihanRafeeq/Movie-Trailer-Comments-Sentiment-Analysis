{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "2BI906QYyi7G"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/DATASET/malayalam_train (1).tsv', sep='\\t')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/DATASET/malayalam_test_results - malayalam_test_results.tsv', sep='\\t')"
      ],
      "metadata": {
        "id": "kFyvbq12-mIh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the 'id' column from the test data\n",
        "test_data.drop(columns=['id'], inplace=True)"
      ],
      "metadata": {
        "id": "Enjsc-G6_lpO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display one instance from the train and test sets\n",
        "print(\"Train Example:\")\n",
        "print(train_data.sample(1))\n",
        "\n",
        "print(\"\\nTest Example:\")\n",
        "print(test_data.sample(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSAGcCdO-nvn",
        "outputId": "455a2f1d-2550-4740-c6ef-6d975f913c29"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Example:\n",
            "                                text   category\n",
            "1877   Ithu vere level aane makkale.  Positive \n",
            "\n",
            "Test Example:\n",
            "                                                   text  category\n",
            "1110  Ammbo onnum parayan illa enna oru bgm annu cla...  Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique categories in both datasets\n",
        "print(\"Unique categories in training data:\")\n",
        "print(train_data['category'].unique())\n",
        "\n",
        "print(\"\\nUnique categories in test data:\")\n",
        "print(test_data['category'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGINBroqAOjE",
        "outputId": "db35d61e-2399-49ad-8bcc-e50da213b621"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique categories in training data:\n",
            "['Positive ' 'not-malayalam ' 'unknown_state ' 'Mixed_feelings '\n",
            " 'Negative ']\n",
            "\n",
            "Unique categories in test data:\n",
            "['unknown_state' 'Negative' 'not-malayalam' 'Positive' 'Mixed_feelings']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for leading/trailing spaces and strip them\n",
        "train_data['category'] = train_data['category'].str.strip()\n",
        "test_data['category'] = test_data['category'].str.strip()"
      ],
      "metadata": {
        "id": "Y0x7__mlAfoc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the labels\n",
        "le = LabelEncoder()\n",
        "train_data['category'] = le.fit_transform(train_data['category'])\n",
        "test_data['category'] = le.transform(test_data['category'])  # Use the same encoder for test data"
      ],
      "metadata": {
        "id": "aMpNd_uc-pgZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into features and labels\n",
        "X_train = train_data['text'].values\n",
        "y_train = train_data['category'].values\n",
        "X_test = test_data['text'].values\n",
        "y_test = test_data['category'].values"
      ],
      "metadata": {
        "id": "ojDrdMeK-sGb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "z7Tjdxgc-uku"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences\n",
        "maxlen = 100  # Maximum length of sequences\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "PK_LrDr--wIg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=maxlen))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dropout(0.5))  # Dropout to prevent overfitting\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(le.classes_), activation='softmax'))  # Number of classes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAvwEssG-xpd",
        "outputId": "5d12d9ea-c295-449d-b21a-91adf2aca10e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "history = model.fit(X_train_pad, y_train, validation_split=0.2, epochs=10, batch_size=32, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWA3wbWH-zQK",
        "outputId": "89dabc1e-5e91-44b8-8402-714fb2bc537d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 133ms/step - accuracy: 0.3851 - loss: 1.4684 - val_accuracy: 0.4367 - val_loss: 1.3111\n",
            "Epoch 2/10\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.5566 - loss: 1.2051 - val_accuracy: 0.6519 - val_loss: 0.9115\n",
            "Epoch 3/10\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 121ms/step - accuracy: 0.7853 - loss: 0.6837 - val_accuracy: 0.6550 - val_loss: 0.8859\n",
            "Epoch 4/10\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 122ms/step - accuracy: 0.8616 - loss: 0.4480 - val_accuracy: 0.6591 - val_loss: 0.9517\n",
            "Epoch 5/10\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 124ms/step - accuracy: 0.9011 - loss: 0.3115 - val_accuracy: 0.6529 - val_loss: 1.0484\n",
            "Epoch 6/10\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 123ms/step - accuracy: 0.9466 - loss: 0.2081 - val_accuracy: 0.6457 - val_loss: 1.2088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test_pad)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Get original class labels from LabelEncoder\n",
        "class_labels = le.inverse_transform(np.unique(y_test))\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes, target_names=class_labels))"
      ],
      "metadata": {
        "id": "N9Q4E_Mq-2KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Select one instance from the test set\n",
        "index_to_check = 0  # Change this to any valid index\n",
        "original_text = test_data['text'].iloc[index_to_check]\n",
        "original_category = test_data['category'].iloc[index_to_check]"
      ],
      "metadata": {
        "id": "i9F6ydAM-4N-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the text for prediction\n",
        "text_sequence = tokenizer.texts_to_sequences([original_text])\n",
        "text_padded = pad_sequences(text_sequence, maxlen=maxlen)\n",
        "\n",
        "# Get prediction\n",
        "prediction = model.predict(text_padded)\n",
        "predicted_category_index = np.argmax(prediction, axis=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkyewajs-6Kg",
        "outputId": "7a7e34d4-3d95-4a90-baa0-272586233e19"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map the predicted index back to the category\n",
        "categories = {i: category for i, category in enumerate(le.classes_)}  # Dynamic mapping\n",
        "predicted_category = categories.get(predicted_category_index, \"Unknown category\")\n",
        "\n",
        "# Print the results\n",
        "print(f\"\\nOriginal Text: {original_text}\")\n",
        "print(f\"Original Category: {le.inverse_transform([original_category])[0]}\")\n",
        "print(f\"Predicted Category: {predicted_category}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTPHbRcg-8Fq",
        "outputId": "543f228d-1f24-40bc-f1a4-79dda0a983b2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original Text: Bollywood film Newton inte remake aano?\n",
            "Original Category: 4\n",
            "Predicted Category: 4\n"
          ]
        }
      ]
    }
  ]
}